{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/Users/lorenapacheco/Concordia/Masters/\"\n",
    "file_analysis_folder= base_path + \"BugReportsMining/coverageMining/\"\n",
    "coverage_data_folder = base_path + \"coverage_data/\"\n",
    "out = '/Users/lorenapacheco/Concordia/Masters/BugReportsMining/ochiaiScores/'\n",
    "\n",
    "buggy_commits_info = {\n",
    "    \"fastjson\": {\n",
    "        #\"2306\": \"0c45401c938ef866700e602adda16a4a0f55960e\",\n",
    "        \"2351\": \"8e985930057c21c95a3065ca9f2cad3b5e42d4ba\",\n",
    "        \"3119\": \"307f6637b9f8502a081468443c2b3c85cea5e545\",\n",
    "        \"3280\": \"cc7dfab3dde888b81577fb18c0eb223761b5e31f\",\n",
    "        #\"3309\": \"7ffa2a013be4401df24455c2cefa2a52af5eebbe\",\n",
    "        \"3637\": \"00cdc53606111e7802f8f5559d44feeccba2657f\",\n",
    "    },\n",
    "    \"commons-csv\": {\n",
    "        \"CSV-100\": \"2b5f84ede12cfadd7946ffb07a56709b8322a02f\"\n",
    "    },\n",
    "    \"jsoup\": {\n",
    "        \"1098\": \"fb50d9635874185fc050735057b8a7363cd53f3f\",\n",
    "        \"1218\": \"8d1d503913a68e549b5c4a94717c62cf3f64507a\",\n",
    "        \"1251\": \"de97030ff54ee0bd306cbc58bd8093645cc8a5dc\",\n",
    "        \"1274\": \"de1ced99d4dae991a546534454d5f7d9dc26f0b1\",\n",
    "        \"1324\": \"528ba552b19ab2ae949feecb373ef85a0b126566\",\n",
    "        \"740\": \"222feb1791388d1e94e2c99bb5858cf160904d16\",\n",
    "        \"968\": \"d32321351ced83c7c2edff2abe4a8b2fa17a6bd7\",\n",
    "        \"980\": \"71561e09e0f29ec5fd1bb918206f3d8e42876518\",\n",
    "        \"990\":  \"02668f757c59f0c1a7ad8f3169faf061b4b787c1\"\n",
    "    },\n",
    "    \"junit4\": {\n",
    "        \"1178\": \"c07965ab1b232b04a13ea84fdbcdd8be04ea0182\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastjson ---- 3280\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 1787\n",
      "Number of fake failing tests: 436\n",
      "\n",
      "fastjson ---- 2351\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 676\n",
      "Number of fake failing tests: 1420\n",
      "\n",
      "fastjson ---- 3637\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 1074\n",
      "Number of fake failing tests: 1213\n",
      "\n",
      "fastjson ---- 3119\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 1520\n",
      "Number of fake failing tests: 679\n",
      "\n",
      "commons-csv ---- CSV-100\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 180\n",
      "Number of fake failing tests: 2\n",
      "\n",
      "jsoup ---- 990\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 10\n",
      "Number of fake failing tests: 22\n",
      "\n",
      "jsoup ---- 968\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 7\n",
      "Number of fake failing tests: 24\n",
      "\n",
      "jsoup ---- 980\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 4\n",
      "Number of fake failing tests: 28\n",
      "\n",
      "jsoup ---- 1274\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 18\n",
      "Number of fake failing tests: 15\n",
      "\n",
      "jsoup ---- 1218\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 5\n",
      "Number of fake failing tests: 28\n",
      "\n",
      "jsoup ---- 740\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 5\n",
      "Number of fake failing tests: 21\n",
      "\n",
      "jsoup ---- 1098\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 33\n",
      "Number of fake failing tests: 0\n",
      "\n",
      "jsoup ---- 1324\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 10\n",
      "Number of fake failing tests: 25\n",
      "\n",
      "jsoup ---- 1251\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 15\n",
      "Number of fake failing tests: 18\n",
      "\n",
      "junit4 ---- 1178\n",
      "* Part 1\n",
      "* Part 2\n",
      "* Part 3\n",
      "* Part 4\n",
      "Number of fake passing tests: 0\n",
      "Number of fake failing tests: 1115\n",
      "\n",
      "Execution completed\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "def json_file_to_dict(file):\n",
    "    data = {}\n",
    "    with open(os.path.join(file), 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    fp.close()\n",
    "    return data\n",
    "\n",
    "def dict_to_json_file(file, dic, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    with open(os.path.join(folder, file+'.json'), 'w') as fp:\n",
    "        json.dump(dic, fp, sort_keys=True, indent=4)\n",
    "    fp.close()\n",
    "\n",
    "for bug_report_analysis_file in glob.glob(file_analysis_folder + \"*/*.json\"):\n",
    "    project = bug_report_analysis_file.split(\"/\")[-2]\n",
    "    bug_id = bug_report_analysis_file.split(\"/\")[-1].replace(\".json\",\"\")\n",
    "    print(project + \" ---- \" + bug_id)\n",
    "    analysis_data = json_file_to_dict(bug_report_analysis_file)\n",
    "    buggy_commit = buggy_commits_info [project][bug_id]\n",
    "    coverage_details_folder = coverage_data_folder + project + \"/\" + buggy_commit + \"/details/\"\n",
    "    fake_failed_tests = []\n",
    "    fake_tests_status = []\n",
    "    methods_list = []\n",
    "\n",
    "\n",
    "    print(\"* Part 1\")\n",
    "    for st_entry in analysis_data.keys():\n",
    "        if \"unique_tests_that_cover_the_method\" in analysis_data[st_entry] and analysis_data[st_entry][\"unique_tests_that_cover_the_method\"] != []:\n",
    "            fake_failed_tests += analysis_data[st_entry][\"unique_tests_that_cover_the_method\"]\n",
    "    if not fake_failed_tests:\n",
    "        for st_entry in analysis_data.keys():\n",
    "            if analysis_data[st_entry][\"tests_that_cover_the_method\"] != \"N/A\":\n",
    "                fake_failed_tests += analysis_data[st_entry][\"tests_that_cover_the_method\"]\n",
    "    fake_failed_tests = list(set(fake_failed_tests))\n",
    "\n",
    "    print(\"* Part 2\")\n",
    "    for test_coverage_file in glob.glob(coverage_details_folder + \"*.json\"):\n",
    "        test_file_name = test_coverage_file.split(\"/\")[-1]\n",
    "        if test_file_name in fake_failed_tests:\n",
    "            fake_tests_status.append((test_file_name, 1)) # error flag\n",
    "        else:\n",
    "            if \"coverage_details\" not in test_file_name:\n",
    "                fake_tests_status.append((test_file_name, 0)) # no error flag\n",
    "        coverage_data = json_file_to_dict(test_coverage_file)\n",
    "        if \"coverage_details\" not in test_file_name:\n",
    "            for method_id in coverage_data[\"covered_stats\"].keys():\n",
    "                method_name = method_id\n",
    "                if \"(\" in method_name:\n",
    "                    method_name = method_name.split(\"(\")[0]\n",
    "                else:\n",
    "                    method_name = method_name.split(\" {\")[0]\n",
    "                try:\n",
    "                    method_name = method_name.split(\".\")[-2] + \".\" + method_name.split(\".\")[-1]\n",
    "                except:\n",
    "                    print(\"#####\")\n",
    "                    print(method_name)\n",
    "                    print(method_id)\n",
    "                if method_name not in methods_list:\n",
    "                    methods_list.append(method_name)\n",
    "\n",
    "    print(\"* Part 3\")\n",
    "    # Pre-populating the matrix\n",
    "    methods_execution_matrix = []\n",
    "    for i in range(0, len(fake_tests_status)):\n",
    "        pre_population_list_auxiliar=[]\n",
    "        for j in range(0, len(methods_list)):\n",
    "            pre_population_list_auxiliar.append(0)\n",
    "        methods_execution_matrix.append(pre_population_list_auxiliar)\n",
    "\n",
    "\n",
    "    for test_pos in range(0, len(fake_tests_status)):\n",
    "        test = fake_tests_status[test_pos]\n",
    "        test_name = test[0].replace(\"[\", \"*\").replace(\"]\", \"*\")\n",
    "        test_coverage_file = glob.glob(coverage_details_folder + test_name)[0]\n",
    "        test_coverage_data = json_file_to_dict(test_coverage_file)\n",
    "        for method_pos in range(0, len(methods_list)):\n",
    "            method = methods_list[method_pos]\n",
    "            for method_covered_by_the_test in test_coverage_data[\"covered_stats\"].keys():\n",
    "                if \".\" + method + \"(\"  in method_covered_by_the_test or \".\" + method + \" {\" in method_covered_by_the_test:\n",
    "                    methods_execution_matrix[test_pos][method_pos] = 1\n",
    "                    break\n",
    "\n",
    "\n",
    "    print(\"* Part 4\")\n",
    "    methods_ochiai_scores = {}\n",
    "    for method_pos2 in range(0, len(methods_list)):\n",
    "        n00 = 0\n",
    "        n01 = 0\n",
    "        n10 = 0\n",
    "        n11 = 0\n",
    "        s_o = 0\n",
    "        method_name = methods_list[method_pos2]\n",
    "        for test_pos2 in range(0, len(fake_tests_status)):\n",
    "            if methods_execution_matrix[test_pos2][method_pos2] == 1:\n",
    "                if fake_tests_status[test_pos2][1] == 1:\n",
    "                    n11 += 1\n",
    "                else:\n",
    "                    n10 += 1\n",
    "            else:\n",
    "                if fake_tests_status[test_pos2][1] == 1:\n",
    "                    n01 += 1\n",
    "                else:\n",
    "                    n00 += 1\n",
    "        try:\n",
    "            s_o = n11/math.sqrt((n11+n01)*(n11+n10))\n",
    "        except ZeroDivisionError:\n",
    "            s_o = 0\n",
    "        methods_ochiai_scores[method_name] = s_o\n",
    "\n",
    "    print(\"Number of fake passing tests: \" + str(len(fake_tests_status)-len(fake_failed_tests)))\n",
    "    print(\"Number of fake failing tests: \" + str(len(fake_failed_tests)) + \"\\n\")\n",
    "    dict_to_json_file(bug_id, methods_ochiai_scores, out + project + \"/\")\n",
    "\n",
    "print(\"Execution completed\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
