{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bfd7cb-bff6-497d-a5d2-d9a145606a64",
   "metadata": {},
   "source": [
    "#### **Var definitions**\n",
    "Change it whenever necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e2af876-773e-4cd7-8153-02aac2680c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_oauth_token = \"token <PLACE_HOLDER>\" #TODO: delete before commiting the code\n",
    "repo = \"junit-team/junit4\"\n",
    "out = '/Users/lorenapacheco/Concordia/Masters/BugReportsMining/bug-reports/'\n",
    "repo_name= repo.split('/')[1]\n",
    "proj = repo_name\n",
    "base_path = '/Users/lorenapacheco/Concordia/Masters/'\n",
    "out_commits_dir = base_path + \"BugReportsMining/commits/\" + repo_name\n",
    "proj_path = base_path + \"open_source_repos_being_studied/\" + repo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c51f8-9ac2-44ae-b686-173e38846576",
   "metadata": {},
   "source": [
    "#### **Bug reports mining**\n",
    "Getting all the Github **issues** from the project that are **closed** and have the **bug**'s label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8861b339-ca0f-47cd-a74c-9f5d3dadb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1616, 1508, 1507, 1462, 1370, 1365, 1363, 1334, 1320, 1290, 1238, 1236, 1224, 1213, 1192, 1189, 1178, 1083, 1073, 1014, 896, 894, 449, 441, 379, 359, 350, 338, 333, 332, 311, 309, 303, 296, 295, 292, 289, 262, 260, 258, 257, 248, 242, 235, 227, 226, 225, 220, 219, 218, 209, 208, 192, 191, 188, 187, 177, 165, 150, 134, 131, 125, 121, 120, 119, 105, 104, 98, 96, 94, 89, 88, 84, 82, 81, 76, 74, 73, 62, 61, 55, 49, 48, 42, 39, 38, 35, 33, 28, 23]\n",
      "\n",
      "Number of issues: 90\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "def get_git_closed_bug_issues(repo, media_type = \"application/vnd.github+json\"):\n",
    "    issue_numbers_list = []\n",
    "    current_page=1\n",
    "    pagination_end = False\n",
    "    \n",
    "    #iteration throught the pagination\n",
    "    while not pagination_end:\n",
    "        issues_json = requests.get(\n",
    "            \"https://api.github.com/repos/\"+repo+\"/issues?state=closed&labels=bug&page=\"+str(current_page),\n",
    "            headers={\n",
    "                'Accept': media_type,\n",
    "                'Authorization': access_oauth_token\n",
    "            }\n",
    "        ).json()\n",
    "        if len(issues_json) > 0:\n",
    "            for issue in issues_json:\n",
    "                issue_numbers_list.append(issue[\"number\"])\n",
    "            current_page = current_page + 1\n",
    "        else:\n",
    "            pagination_end = True\n",
    "            \n",
    "    return issue_numbers_list\n",
    "\n",
    "\n",
    "issue_numbers_list = get_git_closed_bug_issues(repo)\n",
    "print(issue_numbers_list)\n",
    "print(\"\\nNumber of issues: \" + str(len(issue_numbers_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09070d40-c72d-44c4-9002-acc2c6af99b3",
   "metadata": {},
   "source": [
    "#### **Bug reports content extraction**\n",
    "Extraction the content of each of these bug reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0c4105b-f22d-4931-817c-8fdb09fc9cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed\n"
     ]
    }
   ],
   "source": [
    "output_folder = out + repo_name+ '/'\n",
    "\n",
    "def git_request_br_json(issue_n, repo, media_type = 'application/vnd.github.v3+json'):\n",
    "    retrieved_json = requests.get(\n",
    "        'https://api.github.com/repos/'+repo+'/issues/'+str(issue_n),\n",
    "        headers={\n",
    "            'Accept': media_type,\n",
    "            'Authorization': access_oauth_token\n",
    "        }\n",
    "    ).json()\n",
    "    #pprint.pprint(retrieved_json)\n",
    "    \n",
    "    if 'comments_url' not in retrieved_json:\n",
    "        return\n",
    "    \n",
    "    comment_url = retrieved_json['comments_url']\n",
    "    retrieved_comments = requests.get(\n",
    "        comment_url,\n",
    "        headers={\n",
    "            'Accept': media_type,\n",
    "            'Authorization': access_oauth_token\n",
    "        }\n",
    "    ).json()\n",
    "    retrieved_json['comments_content'] = retrieved_comments\n",
    "    return retrieved_json\n",
    "\n",
    "def dict_to_json_file(file, dic, folder=output_folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    with open(os.path.join(folder, file+'.json'), 'w') as fp:\n",
    "        json.dump(dic, fp, sort_keys=True, indent=4)\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "for issue_number in issue_numbers_list:\n",
    "    try:\n",
    "        retrieved_json = git_request_br_json(issue_number, repo)\n",
    "    except ConnectionError:\n",
    "        print('ConnectionError', repo, issue_number)\n",
    "        break\n",
    "\n",
    "    if not retrieved_json:\n",
    "        print('Json not retrieved, something might be wrong')\n",
    "        continue\n",
    "\n",
    "    dict_to_json_file(repo_name+'-'+str(issue_number), retrieved_json)\n",
    "print (\"Extraction completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed1589-b3fd-47d8-99c5-74281107c879",
   "metadata": {},
   "source": [
    "#### **Filtering for logs and stack traces**\n",
    "Filtering only the bug reports with **logs** and **stack traces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58a404ea-f722-4e74-a151-138d583d3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug reports with logs:0\n",
      "Bug reports with stack traces:12\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# global dict of a dict for storing the log\n",
    "bug_report_log = defaultdict(dict)\n",
    "bug_report_stack_trace = defaultdict(dict)\n",
    "\n",
    "def json_file_to_dict(file):\n",
    "    data = {}\n",
    "    with open(os.path.join(output_folder, file+'.json'), 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    fp.close()\n",
    "    return data\n",
    "\n",
    "def find_regex(regex, var,file_name, text_content):\n",
    "    results = re.finditer(regex, text_content)\n",
    "    if results:\n",
    "        for log in results:\n",
    "            bug_name = file_name.split('-')[1]\n",
    "            var[proj][bug_name] = log.group() \n",
    "            \n",
    "            \n",
    "def find_logs_and_stack_traces (file_name, text_content):\n",
    "    stack_trace_regex = r'(?m)^.*?Exception.*(?:\\n+^\\s*at .*)+'\n",
    "    logs_regex = r'(ERROR|INFO|WARN|DEBUG|FATAL)\\s+(?P<class>\\w+(\\.\\w+)*)'\n",
    "    find_regex(logs_regex, bug_report_log,file_name, text_content)\n",
    "    find_regex(stack_trace_regex, bug_report_stack_trace,file_name, text_content)\n",
    "    \n",
    "\n",
    "# for every .json in bug-reports folder\n",
    "for file in glob.glob(output_folder +'/*.json'):\n",
    "    file_name = os.path.basename(file).replace('.json', '')\n",
    "    proj = file_name.replace('-'+file_name.split('-')[-1], '').lower()\n",
    "    bug_report = json_file_to_dict(file.replace('.json', ''))\n",
    "    if not bug_report:\n",
    "        continue\n",
    "    \n",
    "    title = bug_report['title'] if bug_report['title'] else \"\"\n",
    "    description = bug_report['body'] if bug_report['body'] else \"\"\n",
    "    text_content = title + '\\n' + description + '\\n' + '\\n'.join([comment['body'] for comment in bug_report['comments_content'] if 'body' in comment and comment['body']])\n",
    "    \n",
    "    find_logs_and_stack_traces(file_name, text_content)\n",
    "\n",
    "print(\"Bug reports with logs:\" + str(len(bug_report_log[proj])))\n",
    "print(\"Bug reports with stack traces:\" + str(len(bug_report_stack_trace[proj])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627054e6-21b9-4327-8c29-7166c5863b4b",
   "metadata": {},
   "source": [
    "#### **Commits search**\n",
    "Searching for the respective commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ef4e752-9ebf-4602-8600-36dc545b5db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete\n",
      "Number obtained: 11\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import quote\n",
    "\n",
    "bug_reports_with_logs_commits = defaultdict(dict)\n",
    "bug_reports_with_stack_traces_commits = defaultdict(dict)\n",
    "cont = 0\n",
    "\n",
    "def get_bug_report_commit(bug, proj_path):\n",
    "    os.chdir(proj_path)\n",
    "    log_grep_command = \"git log --grep=\"+ bug+\" --pretty=format:\\\"%H\\\" >> commit_output\"\n",
    "    os.system(log_grep_command)\n",
    "    lines = []\n",
    "    with open(\"commit_output\", 'r') as fp:\n",
    "        lines =fp.readlines()\n",
    "        fp.close()\n",
    "    os.system(\"rm commit_output\")\n",
    "    if (lines):\n",
    "        commit_hash = lines[0]\n",
    "        return(commit_hash)\n",
    "    return \"\"\n",
    "\n",
    "for bug in bug_report_log[proj].keys():\n",
    "    commit = get_bug_report_commit(bug, proj_path)\n",
    "    if (commit != \"\"):\n",
    "        content = {\n",
    "            \"log\": bug_report_log[proj][bug],\n",
    "            \"commit\": commit.strip()\n",
    "        }\n",
    "        bug_reports_with_logs_commits[bug] = content\n",
    "        cont = cont + 1\n",
    "\n",
    "for bug in bug_report_stack_trace[proj].keys():\n",
    "    commit = get_bug_report_commit(bug, proj_path)\n",
    "    if (commit != \"\"):\n",
    "        content = {\n",
    "            \"stack_trace\": bug_report_stack_trace[proj][bug],\n",
    "            \"commit\": commit.strip()\n",
    "        }\n",
    "        bug_reports_with_stack_traces_commits[bug] = content\n",
    "        cont = cont + 1\n",
    "\n",
    "if bug_reports_with_logs_commits:\n",
    "    dict_to_json_file(\"bug_reports_with_logs_commits\", bug_reports_with_logs_commits, out_commits_dir)\n",
    "if bug_reports_with_stack_traces_commits:\n",
    "    dict_to_json_file(\"bug_reports_with_stack_traces_commits\", bug_reports_with_stack_traces_commits, out_commits_dir)\n",
    "\n",
    "print(\"Extraction complete\")\n",
    "print(\"Number obtained: \" + str(cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5309b9-08f2-459d-84ea-31a1b10d01d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
